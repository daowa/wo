{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "march_import\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "print 'march_import'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utils\n",
    "## chinese decode \n",
    "def cn(s):\n",
    "#     return s.decode('utf8')\n",
    "    return s\n",
    "## 字符串类型转换为类别的数字编码\n",
    "dict_short_url  = {'init':0} #和短地址一样，统一记录使用过的int\n",
    "dict_short_url_index = {0: 'init'}\n",
    "def getShortUrl(s):\n",
    "    # 未记录，则添加记录\n",
    "    if dict_short_url.has_key(s) == False:\n",
    "        dict_short_url[s] = max(dict_short_url.values())+1\n",
    "        dict_short_url_index[dict_short_url[s]] = s\n",
    "    return dict_short_url[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "march_load_data\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "# trainData means rawdata, X_train means cross_validation data\n",
    "# trainData = pd.merge(pd.read_csv(cn('E:\\\\work\\\\联通+旅游\\\\data\\\\1\\\\train_x.csv'),encoding=\"gb2312\"), pd.read_csv(cn('E:\\\\work\\\\联通+旅游\\\\data\\\\1\\\\train_y.csv'),encoding=\"gb2312\"), on=cn('用户标识'))\n",
    "# testData = pd.read_csv(cn('E:\\\\work\\\\联通+旅游\\\\data\\\\1\\\\test_x.csv'),encoding=\"gb2312\")\n",
    "trainData = pd.merge(pd.read_csv('/data/topic1/train_x.csv'), pd.read_csv('/data/topic1/train_y.csv'), on='用户标识')\n",
    "testData = pd.read_csv('/data/topic1/test_x.csv')\n",
    "print 'march_load_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读入外部特征\n",
    "## 训练集\n",
    "trainData = pd.merge(trainData, pd.read_csv('/data/topic1/feature_countapppv.csv'), on='用户标识')\n",
    "trainData = pd.merge(trainData, pd.read_csv('/data/topic1/feature_countapp.csv'), on='用户标识')\n",
    "trainData = pd.merge(trainData, pd.read_csv('/data/topic1/feature_countoutprovince.csv'), on='用户标识')\n",
    "trainData = pd.merge(trainData, pd.read_csv('/data/topic1/feature_countwebpv.csv'), on='用户标识')\n",
    "trainData = pd.merge(trainData, pd.read_csv('/data/topic1/feature_countweb.csv'), on='用户标识')\n",
    "trainData = pd.merge(trainData, pd.read_csv('/data/topic1/feature_countgroupticket'), on='用户标识')\n",
    "trainData = pd.merge(trainData, pd.read_csv('/data/topic1/feature_countgrouptraffic'), on='用户标识')\n",
    "trainData = pd.merge(trainData, pd.read_csv('/data/topic1/feature_countgroupfff'), on='用户标识')\n",
    "trainData = pd.merge(trainData, pd.read_csv('/data/topic1/feature_countgrouphotel'), on='用户标识')\n",
    "trainData = pd.merge(trainData, pd.read_csv('/data/topic1/feature_countgroupweather'), on='用户标识')\n",
    "trainData = pd.merge(trainData, pd.read_csv('/data/topic1/feature_cluster.csv'), on='用户标识')\n",
    "trainData = pd.merge(trainData, pd.read_csv('/data/topic1/feature_outprovince.csv'), on='用户标识')\n",
    "trainData = pd.merge(trainData, pd.read_csv('/data/topic1/feature_topweb.csv'), on='用户标识')\n",
    "trainData = pd.merge(trainData, pd.read_csv('/data/topic1/feature_webcluster.csv'), on='用户标识')\n",
    "trainData = pd.merge(trainData, pd.read_csv('/data/topic1/feature_maxgroup.csv'), on='用户标识')\n",
    "## 测试集\n",
    "testData = pd.merge(testData, pd.read_csv('/data/topic1/feature_test_countapppv.csv'), on='用户标识')\n",
    "testData = pd.merge(testData, pd.read_csv('/data/topic1/feature_test_countapp.csv'), on='用户标识')\n",
    "testData = pd.merge(testData, pd.read_csv('/data/topic1/feature_test_countoutprovince.csv'), on='用户标识')\n",
    "testData = pd.merge(testData, pd.read_csv('/data/topic1/feature_test_countwebpv.csv'), on='用户标识')\n",
    "testData = pd.merge(testData, pd.read_csv('/data/topic1/feature_test_countweb.csv'), on='用户标识')\n",
    "testData = pd.merge(testData, pd.read_csv('/data/topic1/feature_test_countgroupticket'), on='用户标识')\n",
    "testData = pd.merge(testData, pd.read_csv('/data/topic1/feature_test_countgrouptraffic'), on='用户标识')\n",
    "testData = pd.merge(testData, pd.read_csv('/data/topic1/feature_test_countgroupfff'), on='用户标识')\n",
    "testData = pd.merge(testData, pd.read_csv('/data/topic1/feature_test_countgrouphotel'), on='用户标识')\n",
    "testData = pd.merge(testData, pd.read_csv('/data/topic1/feature_test_countgroupweather'), on='用户标识')\n",
    "testData = pd.merge(testData, pd.read_csv('/data/topic1/feature_test_cluster.csv'), on='用户标识')\n",
    "testData = pd.merge(testData, pd.read_csv('/data/topic1/feature_test_outprovince.csv'), on='用户标识')\n",
    "testData = pd.merge(testData, pd.read_csv('/data/topic1/feature_test_topweb.csv'), on='用户标识')\n",
    "testData = pd.merge(testData, pd.read_csv('/data/topic1/feature_test_webcluster.csv'), on='用户标识')\n",
    "testData = pd.merge(testData, pd.read_csv('/data/topic1/feature_test_maxgroup.csv'), on='用户标识')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 生成特征\n",
    "## 训练集\n",
    "trainData['phone_brand'] = trainData[cn('手机品牌')].apply(getShortUrl)\n",
    "trainData['phone_model_number'] = trainData[cn('手机终端型号')].apply(getShortUrl)\n",
    "trainData['if_cross_province'] = trainData[cn('是否有跨省行为')].apply(getShortUrl)\n",
    "trainData['if_cross_conuntry'] = trainData[cn('是否有出境行为')].apply(getShortUrl)\n",
    "trainData['topweb'] = trainData['topweb'].apply(getShortUrl)\n",
    "## 测试集\n",
    "testData['phone_brand'] = testData[cn('手机品牌')].apply(getShortUrl)\n",
    "testData['phone_model_number'] = testData[cn('手机终端型号')].apply(getShortUrl)\n",
    "testData['if_cross_province'] = testData[cn('是否有跨省行为')].apply(getShortUrl)\n",
    "testData['if_cross_conuntry'] = testData[cn('是否有出境行为')].apply(getShortUrl)\n",
    "testData['topweb'] = testData['topweb'].apply(getShortUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData.drop([cn('手机品牌'), cn('是否有跨省行为'), cn('是否有出境行为'), cn('漫入省份'), cn('漫出省份'), cn('手机终端型号')], axis=1, inplace=True)\n",
    "testData.drop([cn('手机品牌'), cn('是否有跨省行为'), cn('是否有出境行为'), cn('漫入省份'), cn('漫出省份'), cn('手机终端型号')], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 修改列名， lgb不支持中文列名\n",
    "dict_new_columns = {}\n",
    "for i in trainData.drop([cn('用户标识'),cn('是否去过迪士尼')],axis=1).columns:\n",
    "    dict_new_columns[i] = str(getShortUrl(i))\n",
    "trainData.rename(columns=dict_new_columns, inplace = True)\n",
    "testData.rename(columns=dict_new_columns, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 声明类别变量,\n",
    "temp_categorical_feature = [cn('性别'),cn('大致消费水平'),'phone_brand','phone_model_number','if_cross_province','if_cross_conuntry',\n",
    "                           'hainan','shanghai','neimenggu','xizang','gansu','henan','cluster','webcluster', 'topweb','maxgroup']\n",
    "list_categorical_feature = [str(dict_short_url[item]) for item in temp_categorical_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 一次训练\n",
    "# print 'march_init_model'\n",
    "# train_data = lgb.Dataset(trainData.drop([cn('用户标识'),cn('是否去过迪士尼')],axis=1).values, label=trainData[cn('是否去过迪士尼')], feature_name=list(trainData.drop([cn('用户标识'),cn('是否去过迪士尼')],axis=1).columns), categorical_feature=list_categorical_feature)\n",
    "# param = {'application': 'binary', 'boosting': 'gbdt', 'num_leaves':127, 'num_trees':1000, 'objective':'binary', 'min_child_samples':400, 'max_bin': 250, 'max_depth':-1, \n",
    "#          'feature_fraction':1, 'metric':'auc','subsample':0.9, 'lambda_l1':1.5, 'lambda_l2':20, 'min_data_in_bin':100,\n",
    "#         'bagging_fraction':1, 'bagging_freq':1, 'learning_rate':0.025}\n",
    "# estimators = lgb.train(param,train_data,num_boost_round=150)\n",
    "# ypred = estimators.predict(testData.drop([cn('用户标识')],axis=1).values)\n",
    "# print 'march_model_done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "march_init_model_avg\n",
      "march_model_done\n"
     ]
    }
   ],
   "source": [
    "# 多次训练取平均\n",
    "print 'march_init_model_avg'\n",
    "list_ypred = []\n",
    "for i in range(3):\n",
    "    this_round_data = trainData.sample(frac=0.9)\n",
    "    train_data = lgb.Dataset(this_round_data.drop([cn('用户标识'),cn('是否去过迪士尼')],axis=1).values, label=this_round_data[cn('是否去过迪士尼')], feature_name=list(this_round_data.drop([cn('用户标识'),cn('是否去过迪士尼')],axis=1).columns), categorical_feature=list_categorical_feature)\n",
    "    param = {'application': 'binary', 'boosting': 'dart', 'num_leaves':127, 'num_trees':1000, 'objective':'binary', 'min_child_samples':400, 'max_bin': 250, 'max_depth':-1, \n",
    "         'feature_fraction':1, 'metric':'auc','subsample':0.9, 'lambda_l1':1.5, 'lambda_l2':20, 'min_data_in_bin':100,\n",
    "        'bagging_fraction':1, 'bagging_freq':1, 'learning_rate':0.05}\n",
    "    estimators = lgb.train(param,train_data,num_boost_round=486)\n",
    "    ypred = estimators.predict(testData.drop([cn('用户标识')],axis=1).values)\n",
    "    list_ypred.append(ypred)\n",
    "ypred =  np.asarray(list_ypred).mean(axis=0)\n",
    "print 'march_model_done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出csv结果\n",
    "output = pd.DataFrame({'IMEI': testData[cn('用户标识')].values,'SCORE':ypred})\n",
    "# output.to_csv(cn('E:\\\\work\\\\联通+旅游\\\\data\\\\1\\\\result.csv'), index=False, float_format='%.5f')\n",
    "output.to_csv('/data/topic1/result_lgb1.csv', index=False, float_format='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
